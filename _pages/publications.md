---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}

<div class='paper-box-text' markdown="1">

### 2025

- Zhong-Zhi Li, Duzhen Zhang, Ming-Liang Zhang, Jiaxin Zhang, Zengyan Liu, Yuxuan Yao, Haotian Xu, Junhao Zheng, Pei-Jie Wang, Xiuyi Chen, Yingying Zhang, Fei Yin, Jiahua Dong, Zhiwei Li, `BaoLong Bi`, Ling-Rui Mei, Junfeng Fang, Zhijiang Guo, Le Song, Cheng-Lin Liu. **From System 1 to System 2: A Survey of Reasoning Large Language Models**. [[arxiv]](https://arxiv.org/abs/2502.17419) [[paper]](https://arxiv.org/pdf/2502.17419)

- Cheng Wang, Yue Liu, `Baolong Bi`, Duzhen Zhang, Zhongzhi Li, Junfeng Fang. **Safety in Large Reasoning Models: A Survey**. [[arxiv]](https://arxiv.org/abs/2504.17704) [[paper]](https://arxiv.org/pdf/2504.17704)

- Lingrui Mei, Shenghua Liu, Yiwei Wang, `Baolong Bi`, Yuyao Ge, Jun Wan, Yurong Wu, Xueqi Cheng. **a1: Steep Test-time Scaling Law via Environment Augmented Generation**. [[arxiv]](https://arxiv.org/abs/2504.14597) [[paper]](https://arxiv.org/pdf/2504.14597)

- Yilong Xu, Jinhua Gao, Xiaoming Yu, Yuanhai Xue, `Baolong Bi`, Huawei Shen, Xueqi Cheng. **Training a Utility-based Retriever Through Shared Context Attribution for Retrieval-Augmented Language Models**. [arxiv](https://arxiv.org/abs/2504.00573) [paper](https://arxiv.org/pdf/2504.00573)

- Yue Liu, Jiaying Wu, Yufei He, Hongcheng Gao, Hongyu Chen, `Baolong Bi`, Jiaheng Zhang, Zhiqi Huang, Bryan Hooi. **Efficient Inference for Large Reasoning Models: A Survey**. [arxiv](https://arxiv.org/abs/2503.23077) [paper](https://arxiv.org/pdf/2503.23077)

- Hongcheng Gao, Jiashu Qu, Jingyi Tang, `Baolong Bi`, Yue Liu, Hongyu Chen, Li Liang, Li Su, Qingming Huang. **Exploring Hallucination of Large Multimodal Models in Video Understanding: Benchmark, Analysis and Mitigation**. [arxiv](https://arxiv.org/abs/2503.19622) [paper](https://arxiv.org/pdf/2503.19622) [huggingface](https://huggingface.co/papers/2503.19622) [github](https://github.com/Hongcheng-Gao/HAVEN/tree/main)

- Yuyao Ge, Shenghua Liu, Yiwei Wang, Lingrui Mei, Lizhe Chen, `Baolong Bi`, Xueqi Cheng. **Innate Reasoning is Not Enough: In-Context Learning Enhances Reasoning Large Language Models with Less Overthinking**. [arxiv](https://arxiv.org/abs/2503.19602) [paper](https://arxiv.org/pdf/2503.19602)

- `Baolong Bi`, Shenghua Liu, Yiwei Wang, Yilong Xu, Junfeng Fang, Lingrui Mei, Xueqi Cheng. **Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models**.
[arxiv](https://arxiv.org/abs/2503.15888) [paper](https://arxiv.org/pdf/2503.15888)

- Shiyu Ni, Keping Bi, Jiafeng Guo, Lulu Yu, `Baolong Bi`, Xueqi Cheng. **Towards Fully Exploiting LLM Internal States to Enhance Knowledge
Boundary Perception**. [[arxiv]](https://arxiv.org/abs/2502.11677) [[paper]](https://arxiv.org/pdf/2502.11677)

- Zherui Li, Houcheng Jiang, Hao Chen, `Baolong Bi`, Zhenhong Zhou, Fei Sun, Junfeng Fang, Xiang Wang. **Reinforced Lifelong Editing for Language Models**. [[arxiv]](https://arxiv.org/abs/2502.05759) [[paper]](https://arxiv.org/pdf/2502.05759)

- Tianyu Zhang, Junfeng Fang, Houcheng Jiang, `Baolong Bi`, Xiang Wang, Xiangnan He. **Explainable and Efficient Editing for Large Language Models**. [[arxiv]](https://openreview.net/forum?id=iAn7rlIfgc#discussion) [[paper]](https://openreview.net/pdf?id=iAn7rlIfgc)

### 2024
- `Baolong Bi`, Shaohan Huang, Yiwei Wang, Tianchi Yang, Zihan Zhang, Haizhen Huang, Lingrui Mei, Junfeng Fang, Zehao Li, Furu Wei. **Context-DPO: Aligning Language Models for Context-Faithfulness**. [[page]](https://byronbbl.github.io/context-dpo.io/) [[arxiv]](https://www.arxiv.org/abs/2412.15280) [[paper]](https://arxiv.org/pdf/2412.15280)

-	Zehao Li, Wenwei Han, Yujun Cai, Hao Jiang, `Baolong Bi`, Shuqin Gao, Honglong Zhao, Zhaoqi Wang. **GradiSeg: Gradient-Guided Gaussian Segmentation with Enhanced 3D Boundary Precision**.
[[arxiv]](https://arxiv.org/abs/2412.00392) [[paper]](https://arxiv.org/pdf/2412.00392)

-	Yuyao Ge, Shenghua Liu, `Baolong Bi`, Yiwei Wang, Lingrui Mei, Wenjie Feng, Lizhe Chen, Xueqi Cheng. **Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?**.
[[arxiv]](https://arxiv.org/abs/2402.07140) [[paper]](https://arxiv.org/pdf/2402.07140v4)

-	Lingrui Mei, Shenghua Liu, Yiwei Wang, `Baolong Bi`, Ruibin Yuan, Xueqi Cheng. **HiddenGuard: Fine-Grained Safe Generation with Specialized Representation Router**.
[[arxiv]](https://arxiv.org/abs/2410.02684) [[paper]](https://arxiv.org/pdf/2410.02684)

-	`Baolong Bi`, Shenghua Liu, Yiwei Wang, Lingrui Mei, Hongcheng Gao, Junfeng Fang, Xueqi Cheng. **StruEdit: Structured Outputs Enable the Fast and Accurate Knowledge Editing for Large Language Models**.
[[arxiv]](https://arxiv.org/abs/2409.10132) [[paper]](https://arxiv.org/pdf/2409.10132)

-	Yilong Xu, Jinhua Gao, Xiaoming Yu, `Baolong Bi`, Huawei Shen, Xueqi Cheng. **ALiiCE: Evaluating Positional Fine-grained Citation Generation**.
[[arxiv]](https://arxiv.org/abs/2406.13375) [[paper]](https://arxiv.org/pdf/2406.13375)

-	`Baolong Bi`, Shenghua Liu, Yiwei Wang, Lingrui Mei, Hongcheng Gao, Yilong Xu, Xueqi Cheng. **Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities**.
[[arxiv]](https://arxiv.org/abs/2406.12468) [[paper]](https://arxiv.org/pdf/2406.12468)

-	Lingrui Mei, Shenghua Liu, Yiwei Wang, `Baolong Bi`, Jiayi Mao, Xueqi Cheng. **"Not Aligned" is Not "Malicious": Being Careful about Hallucinations of Large Language Models' Jailbreak**.
[[arxiv]](https://arxiv.org/abs/2406.11668) [[paper]](https://arxiv.org/pdf/2406.11668)

-	`Baolong Bi`, Shenghua Liu, Lingrui Mei, Yiwei Wang, Pengliang Ji, Xueqi Cheng. **Decoding by Contrasting Knowledge: Enhancing LLMs' Confidence on Edited Facts**.
[[page]](https://deck-llm.meirtz.com/) [[arxiv]](https://arxiv.org/abs/2405.11613) [[paper]](https://arxiv.org/pdf/2405.11613.pdf)

-	`Baolong Bi`, Shenghua Liu, Yiwei Wang, Lingrui Mei, Xueqi Cheng. **Is Factuality Enhancement a Free Lunch For LLMs? Better Factuality Can Lead to Worse Context-Faithfulness**.
[[arxiv]](https://arxiv.org/abs/2404.00216) [[paper]](https://arxiv.org/pdf/2404.00216.pdf)

-	`Baolong Bi`, Shenghua Liu, Yiwei Wang, Lingrui Mei, Xueqi Cheng. **LPNL: Scalable Link Prediction with Large Language Models**.
[[arxiv]](https://arxiv.org/abs/2401.13227) [[paper]](https://arxiv.org/pdf/2401.13227.pdf)

-	Lingrui Mei, Shenghua Liu, Yiwei Wang, `Baolong Bi`, Xueqi Cheng. **SLANG: New Concept Comprehension of Large Language Models**.
[[arxiv]](https://arxiv.org/abs/2401.12585) [[paper]](https://arxiv.org/pdf/2401.12585.pdf)


</div>


